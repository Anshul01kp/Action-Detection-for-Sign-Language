{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action Detection for Sign Language.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORix55RcV14byTdCnH9ryv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshul01kp/Action-Detection-for-Sign-Language/blob/main/Action_Detection_for_Sign_Language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Install Dependencies"
      ],
      "metadata": {
        "id": "5dPT6XKnrKQe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqEHjOcpk0ao"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "xURM8RF3nSee"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints using MP Holistic"
      ],
      "metadata": {
        "id": "BFfb0Y5crQrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Holistic Model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "# Drawing Utilities\n",
        "mp_drawing = mp.solutions.drawing_utils"
      ],
      "metadata": {
        "id": "r9U0-Nc_rGe2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mediapipe_detection(image, model):\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)    # Color Conversion BGR to RGB\n",
        "  image.flags.writable = False                      # Image is no longer writable\n",
        "  results = model.process(image)                    # Make Prediction\n",
        "  image.flags.writable = True                       # Image is now writable\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)    # Color Conversion RGB to BGR\n",
        "  return image, results"
      ],
      "metadata": {
        "id": "7Tq-uQN_cBoX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_landmarks(image, results):\n",
        "  mp.drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)        # Draw Face Connections\n",
        "  mp.drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)        # Draw Pose Connections\n",
        "  mp.drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)   # Draw Left Hand Connections\n",
        "  mp.drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)  # Draw Right Hand Connections"
      ],
      "metadata": {
        "id": "rA4egx3cdIyu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "  # Draw face connections\n",
        "  mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             ) \n",
        "  # Draw pose connections\n",
        "  mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
        "                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                            ) \n",
        "  # Draw left hand connections\n",
        "  mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
        "                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                            ) \n",
        "  # Draw right hand connections  \n",
        "  mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
        "                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                            ) "
      ],
      "metadata": {
        "id": "uzerjc6HRI_R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Set mediapipe model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()   # Read feed\n",
        "    image, results = mediapipe_detection(frame, holistic)   # Make detections\n",
        "    print(results)\n",
        "\n",
        "    draw_styled_landmarks(image, results)   # Draw landmarks\n",
        "\n",
        "    cv2.imshow('OpenCV Feed', image)    # Show to screen\n",
        "\n",
        "    # Break gracefully\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "  \n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "PAaYFZPUSFoP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_landmarks(frame, results)"
      ],
      "metadata": {
        "id": "B9DZW2p9UDVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "9HvwM6xGULBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "csLYQdtabcoS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}